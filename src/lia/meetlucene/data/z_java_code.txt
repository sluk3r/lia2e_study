package org.sluk3r.lucene;

import java.io.File;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;

import org.apache.commons.math.linear.OpenMapRealVector;
import org.apache.commons.math.linear.RealVectorFormat;
import org.apache.commons.math.linear.SparseRealVector;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.index.TermEnum;
import org.apache.lucene.index.TermFreqVector;
import org.apache.lucene.queryParser.ParseException;
import org.apache.lucene.queryParser.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;
import org.junit.Assert;
import org.junit.Test;

public class TermVectorBasedSimilarityTest {
    static String path = "E:\\sluk3r\\LIAsourcecode\\lia2e\\indexes\\MeetLucene";

    @Test
    public void testSimilarity() throws Exception {
        //IndexReader reader = IndexReader.open(FSDirectory.open(new File("/path/to/my/index")));
        IndexReader reader = IndexReader.open(FSDirectory.open(new File(path)));
        // first find all terms in the index
        Map<String, Integer> terms = new HashMap<String, Integer>();
        TermEnum termEnum = reader.terms(new Term("contents"));
        int pos = 0;
        while (termEnum.next()) {
            Term term = termEnum.term();
            if (!"contents".equals(term.field()))
                break;
            terms.put(term.text(), pos++);
        }
        //int[] docIds = new int[]{31825, 31835, 31706, 30};
        int[] docIds = new int[]{3, 13, 4, 8};
//        int[] docIds = new int[]{1,2,3,4};
        DocVector[] docs = new DocVector[docIds.length];
        int i = 0;
        for (int docId : docIds) {
            TermFreqVector[] tfvs = reader.getTermFreqVectors(docId);
            Assert.assertTrue(tfvs.length == 1);
            docs[i] = new DocVector(terms);
            for (TermFreqVector tfv : tfvs) {
                String[] termTexts = tfv.getTerms();
                int[] termFreqs = tfv.getTermFrequencies();
                Assert.assertEquals(termTexts.length, termFreqs.length);
                for (int j = 0; j < termTexts.length; j++) {
                    docs[i].setEntry(termTexts[j], termFreqs[j]);
                }
            }
            docs[i].normalize();
            i++;
        }
        // now get similarity between doc[0] and doc[1]
        double cosim01 = getCosineSimilarity(docs[0], docs[1]);
        System.out.println("cosim(3,13)=" + cosim01); //cosim(3,13)=0.5083522418079054
        // between doc[0] and doc[2]
        double cosim02 = getCosineSimilarity(docs[0], docs[2]);
        System.out.println("cosim(3,4)=" + cosim02);//cosim(3,4)=0.9924530858284587
        // between doc[0] and doc[3]
        double cosim03 = getCosineSimilarity(docs[0], docs[3]);
        System.out.println("cosim(3,8)=" + cosim03);//cosim(3,8)=0.42733608311522275
        reader.close();
    }

    private double getCosineSimilarity(DocVector d1, DocVector d2) {
        return (d1.vector.dotProduct(d2.vector)) /
                (d1.vector.getNorm() * d2.vector.getNorm());
    }

    private class DocVector {
        public Map<String, Integer> terms;
        public SparseRealVector vector;

        public DocVector(Map<String, Integer> terms) {
            this.terms = terms;
            this.vector = new OpenMapRealVector(terms.size());
        }

        public void setEntry(String term, int freq) {
            if (terms.containsKey(term)) {
                int pos = terms.get(term);
                vector.setEntry(pos, (double) freq);
            }
        }

        public void normalize() {
            double sum = vector.getL1Norm();
            vector = (SparseRealVector) vector.mapDivide(sum);
        }

        public String toString() {
            RealVectorFormat formatter = new RealVectorFormat();
            return formatter.format(vector);
        }
    }


    @Test
    public void testSearche() throws Exception{
        search(path, "patent");
    }



    public static void search(String indexDir, String q)
            throws IOException, ParseException {

        Directory dir = FSDirectory.open(new File(indexDir)); //3
        IndexSearcher is = new IndexSearcher(dir);   //3

        QueryParser parser = new QueryParser(Version.LUCENE_30, // 4
                "contents",  //4
                new StandardAnalyzer(          //4
                        Version.LUCENE_30));  //4
        Query query = parser.parse(q);              //4
        long start = System.currentTimeMillis();
        TopDocs hits = is.search(query, 10); //5
        long end = System.currentTimeMillis();

        System.err.println("Found " + hits.totalHits +   //6
                " document(s) (in " + (end - start) +        // 6
                " milliseconds) that matched query '" +     // 6
                q + "':");                                   // 6

        for(ScoreDoc scoreDoc : hits.scoreDocs) {
            Document doc = is.doc(scoreDoc.doc);               //7
            System.out.println(doc.get("fullpath"));  //8
            System.out.println("id: " + scoreDoc.doc);
        }
        is.close();                                //9
    }
}
